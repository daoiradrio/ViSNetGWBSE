{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from ase.io import read\n",
    "from ViSNetGW.model.visnet import create_model\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(logs_path, ckpt_name):\n",
    "    model_file = f\"{logs_path}/{ckpt_name}.ckpt\"\n",
    "    config_file = f\"{logs_path}/config.yaml\"\n",
    "\n",
    "    cfg = OmegaConf.load(os.path.join(config_file))\n",
    "    model = create_model(cfg)\n",
    "    state_dict = torch.load(model_file, map_location=torch.device(\"cpu\"))\n",
    "    if \"swa\" in model_file:\n",
    "        new_state_dict = {key[7:]: value for key, value in state_dict.items() if \"module\" in key}\n",
    "        model.load_state_dict(new_state_dict)\n",
    "    else:\n",
    "        model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_set, folder, target, limit_mol_size=False):\n",
    "\n",
    "    xyz_path = os.path.join(\"/Volumes/LaCie/test_sets\", test_set, \"mols\")\n",
    "    data_path = os.path.join(\"/Volumes/LaCie/test_sets\", test_set, folder)\n",
    "\n",
    "    xyz_files = os.listdir(xyz_path)\n",
    "    all_mae = []\n",
    "    with torch.no_grad():\n",
    "        for xyz_file in tqdm(xyz_files, leave=False):\n",
    "            mol = xyz_file[:-4]\n",
    "            atoms = read(os.path.join(xyz_path, xyz_file), format=\"xyz\")\n",
    "            if limit_mol_size:\n",
    "                if not (12 <= len(atoms) <= 24):\n",
    "                    continue\n",
    "            #for elem in atoms.get_chemical_symbols():\n",
    "            #    if elem not in [\"H\", \"C\", \"N\", \"O\", \"F\"]:\n",
    "            #        print(elem)\n",
    "            homo_idx = int(np.sum(atoms.get_atomic_numbers()) // 2 - 1) * (folder[:8] != \"E_omol25\")\n",
    "            energies = np.loadtxt(os.path.join(data_path, f\"{mol}.dat\"))\n",
    "            if target == \"homo\":\n",
    "                y = float(energies[homo_idx])\n",
    "            elif target == \"lumo\":\n",
    "                y = float(energies[homo_idx + 1])\n",
    "            elif target == \"gap\":\n",
    "                homo = float(energies[homo_idx])\n",
    "                lumo = float(energies[homo_idx + 1])\n",
    "                y = lumo - homo\n",
    "            Z = torch.from_numpy(atoms.get_atomic_numbers())\n",
    "            R = torch.from_numpy(atoms.get_positions()).to(dtype=torch.float32)\n",
    "            B = torch.zeros((len(atoms),)).to(dtype=torch.int64)\n",
    "            data = {\"z\": Z, \"pos\": R, \"batch\": B}\n",
    "            y_pred, _ = model(data)\n",
    "            y_pred = y_pred.item()\n",
    "            all_mae.append(abs(y_pred - y))\n",
    "    \n",
    "    return all_mae\n",
    "\n",
    "\n",
    "\n",
    "def test_model_gwset(model, target):\n",
    "    base_path = \"/Volumes/LaCie/test_sets/GWSet\"\n",
    "    N = torch.load(os.path.join(base_path, \"N.pt\"))\n",
    "    Z = torch.load(os.path.join(base_path, \"Z.pt\"))\n",
    "    R = torch.load(os.path.join(base_path, \"R.pt\"))\n",
    "    M = torch.load(os.path.join(base_path, \"M.pt\"))\n",
    "    E = torch.load(os.path.join(base_path, f\"{target}.pt\"))\n",
    "\n",
    "    all_mae = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(2885), leave=False):\n",
    "            data = {\"z\": Z[i, M[i]], \"pos\": R[i, M[i], :], \"batch\": torch.tensor([0 for _ in range(N[i].item())])}\n",
    "            y_pred, _ = model(data)\n",
    "            y_pred = y_pred.item()\n",
    "            y = E[i].item()\n",
    "            #print(y_pred, y)\n",
    "            all_mae.append(abs(y_pred - y))\n",
    "    \n",
    "    return all_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar plots showing MAE change per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = \"/Volumes/LaCie/trained_models/ViSNet/gap0M128502532\"\n",
    "ckpt_name = \"model_55_epochs\"\n",
    "model = load_model(logs_path, ckpt_name)\n",
    "\n",
    "logs_path = \"/Volumes/LaCie/trained_models/ViSNet/gap5M128502532_transfer_converged\"\n",
    "ckpt_name = \"model_35_epochs\"\n",
    "pretrained_model = load_model(logs_path, ckpt_name)\n",
    "\n",
    "all_mae = test_model(model, test_set=\"PC9\", folder=\"E_qp\", target=\"gap\", limit_mol_size=False)\n",
    "all_mae_pretrained = test_model(pretrained_model, test_set=\"PC9\", folder=\"E_qp\", target=\"gap\", limit_mol_size=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = \"/Volumes/LaCie/trained_models/ViSNet/gap0M128502532\"\n",
    "ckpt_name = \"model_55_epochs\"\n",
    "model = load_model(logs_path, ckpt_name)\n",
    "\n",
    "logs_path = \"/Volumes/LaCie/trained_models/ViSNet/gap5M128502532_transfer_converged\"\n",
    "ckpt_name = \"model_35_epochs\"\n",
    "pretrained_model = load_model(logs_path, ckpt_name)\n",
    "\n",
    "all_mae = test_model_gwset(model, target=\"GAP\")\n",
    "all_mae_pretrained = test_model_gwset(pretrained_model, target=\"GAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(all_mae)\n",
    "x = [i for i in range(n)]\n",
    "temp = [(x, y) for x, y in sorted(zip(all_mae, all_mae_pretrained), key=lambda pair: pair[0], reverse=True)]\n",
    "no_pretrain, pretrain = zip(*temp)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "font = {\"fontname\": \"Helvetica\", \"fontsize\": 20}\n",
    "cmap = plt.cm.Blues\n",
    "\n",
    "ax.bar(x, height=no_pretrain, align=\"edge\", width=1.05, label=\"Without Pretraining\", color=cmap(0.4))\n",
    "ax.bar(x, height=pretrain, align=\"edge\", width=1.05, label=\"With Pretraining\", color=cmap(0.9))\n",
    "\n",
    "ax.set_title(\"Test\", fontname=\"Helvetica\", fontsize=25)\n",
    "\n",
    "ax.set_xlabel(\"Sample Index\", **font)\n",
    "ax.set_xlim([0, n])\n",
    "xticks = np.arange(stop=n, step=500)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticks, fontname=\"Helvetica\", fontsize=14)\n",
    "\n",
    "ax.set_ylabel(\"MAE [eV]\", **font)\n",
    "ax.set_ylim([0, 2.4])\n",
    "yticks = np.arange(stop=2.6, step=0.2)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.set_yticks(yticks)\n",
    "\n",
    "ax.legend(prop={\"family\": font[\"fontname\"], \"size\": 14})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAE bar plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homo Small and Large Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "font = {\"fontname\": \"Helvetica\", \"fontsize\": 20}\n",
    "\n",
    "# Data\n",
    "categories = [\"Reference\", \"None\", \"Full\", \"Transfer\"]\n",
    "N_pre_values = [\"0\", \"1 000 000\", \"5 000 000\", \"10 000 000\"]\n",
    "\n",
    "data_homo_small = {\n",
    "    \"Test\": {\n",
    "        \"Reference\": [0.0518],\n",
    "        \"None\": [0.2591, 0.2701, 0.2432],\n",
    "        \"Full\": [0.0365, 0.0298, 0.0313],\n",
    "        \"Transfer\": [0.0435, 0.0380, 0.0378],\n",
    "    },\n",
    "    \"PC9\": {\n",
    "        \"Reference\": [0.2074],\n",
    "        \"None\": [0.2910, 0.3071, 0.2720],\n",
    "        \"Full\": [0.0895, 0.0751, 0.0701],\n",
    "        \"Transfer\": [0.0794, 0.0632, 0.0568],\n",
    "    },\n",
    "    \"OE62L\": {\n",
    "        \"Reference\": [0.3751],\n",
    "        \"None\": [0.1694, 0.1652, 0.1629],\n",
    "        \"Full\": [0.1289, 0.0827, 0.1002],\n",
    "        \"Transfer\": [0.1115, 0.0866, 0.0784],\n",
    "    },\n",
    "    \"OE62H\": {\n",
    "        \"Reference\": [0.4833],\n",
    "        \"None\": [0.1474, 0.1189, 0.1220],\n",
    "        \"Full\": [0.1696, 0.1369, 0.1753],\n",
    "        \"Transfer\": [0.1233, 0.1041, 0.0948],\n",
    "    }\n",
    "}\n",
    "\n",
    "data_homo_large = {\n",
    "    \"Test\": {\n",
    "        \"Reference\": [0.0378],\n",
    "        \"None\": [0.2697, 0.2561, 0.2322],\n",
    "        \"Full\": [0.0380, 0.0280, 0.0285],\n",
    "        \"Transfer\": [0.0452, 0.0297, 0.0294],\n",
    "    },\n",
    "    \"PC9\": {\n",
    "        \"Reference\": [0.1973],\n",
    "        \"None\": [0.2980, 0.2914, 0.2668],\n",
    "        \"Full\": [0.0880, 0.0555, 0.0454],\n",
    "        \"Transfer\": [0.0769, 0.0517, 0.0503],\n",
    "    },\n",
    "    \"OE62L\": {\n",
    "        \"Reference\": [0.2375],\n",
    "        \"None\": [0.1714, 0.1588, 0.1662],\n",
    "        \"Full\": [0.1160, 0.0870, 0.0709],\n",
    "        \"Transfer\": [0.1332, 0.0775, 0.0707],\n",
    "    },\n",
    "    \"OE62H\": {\n",
    "        \"Reference\": [0.5183],\n",
    "        \"None\": [0.1565, 0.1686, 0.1334],\n",
    "        \"Full\": [0.1788, 0.1247, 0.1032],\n",
    "        \"Transfer\": [0.1595, 0.1108, 0.1084],\n",
    "    }\n",
    "}\n",
    "\n",
    "data = data_homo_small\n",
    "data_set = \"OE62H\"\n",
    "data = data[data_set]\n",
    "\n",
    "# Gradient colors\n",
    "cmap = plt.cm.Blues\n",
    "colors = [cmap(i) for i in np.linspace(0.35, 1.05, len(N_pre_values))]\n",
    "\n",
    "# Bar geometry\n",
    "bar_width = 0.2         # width of each bar\n",
    "intra_gap = 0.0         # space between bars within a 3-bar group\n",
    "\n",
    "# Group widths\n",
    "W_group = 3*bar_width + 2*intra_gap   # width of groups with 3 bars\n",
    "W_ref   = bar_width                   # width of the single-bar \"Reference\" group\n",
    "\n",
    "# Desired center spacing between multi-bar groups\n",
    "S_groups = 1.0  # distance between centers of None, Full, Transfer\n",
    "\n",
    "# Place centers: keep None, Full, Transfer at 1,2,3; shift Reference so edge gaps match\n",
    "x_groups = np.array([1, 2, 3], dtype=float)\n",
    "x_ref = x_groups[0] - (S_groups - (W_group - W_ref)/2.0)  # = 1 - (1 - (W_group - W_ref)/2)\n",
    "\n",
    "# Offsets for bars inside a 3-bar group (left, middle, right), centered on group tick\n",
    "offsets = np.array([\n",
    "    -W_group/2 + bar_width/2,                       # left bar\n",
    "    -W_group/2 + bar_width/2 + (bar_width + intra_gap),  # middle\n",
    "    -W_group/2 + bar_width/2 + 2*(bar_width + intra_gap) # right\n",
    "])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# --- Plot Reference (single centered bar) ---\n",
    "ax.bar(\n",
    "    x_ref,\n",
    "    data[\"Reference\"][0],\n",
    "    width=bar_width,\n",
    "    label=f\"{N_pre_values[0]}\",\n",
    "    color=colors[0]\n",
    ")\n",
    "\n",
    "# --- Plot other categories (3 bars each), centered on their ticks with intra-group spacing ---\n",
    "for i, (N, color) in enumerate(zip(N_pre_values[1:], colors[1:])):  # i = 0..2\n",
    "    vals = [data[cat][i] for cat in categories[1:]]  # None, Full, Transfer\n",
    "    ax.bar(\n",
    "        x_groups + offsets[i],\n",
    "        vals,\n",
    "        width=bar_width,\n",
    "        label=f\"{N}\",\n",
    "        color=color\n",
    "    )\n",
    "\n",
    "# Axes, ticks, legend\n",
    "ax.set_title(data_set, fontname=\"Helvetica\", fontsize=25)\n",
    "ax.set_xlabel(\"Finetuning\", **font)\n",
    "ax.set_ylabel(\"MAE [eV]\", **font)\n",
    "xticks = np.concatenate(([x_ref], x_groups))\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(categories, fontname=\"Helvetica\", fontsize=14)\n",
    "yticks = np.arange(stop=0.60, step=0.05)\n",
    "ax.set_yticks(yticks)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.set_ylim(0, yticks[-1])\n",
    "\n",
    "legend = ax.legend(title=\"Number Pretraining Samples\", prop={\"family\": font[\"fontname\"], \"size\": 14})\n",
    "legend.get_title().set_fontsize(14)\n",
    "\n",
    "plt.grid(True, axis=\"y\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lumo and Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {\"fontname\": \"Helvetica\", \"fontsize\": 20}\n",
    "\n",
    "# Data (replace with your GAP or LUMO dict)\n",
    "data_lumo = {\n",
    "    \"Test\": {\n",
    "        \"Reference\": [0.0338],\n",
    "        \"None\": [0.7496, 0.7301],\n",
    "        \"Transfer\": [0.0336, 0.0321],\n",
    "    },\n",
    "    \"PC9\": {\n",
    "        \"Reference\": [0.1258],\n",
    "        \"None\": [0.6991, 0.6761],\n",
    "        \"Transfer\": [0.0571, 0.0530],\n",
    "    },\n",
    "    \"OE62L\": {\n",
    "        \"Reference\": [0.3075],\n",
    "        \"None\": [0.4265, 0.4361],\n",
    "        \"Transfer\": [0.1273, 0.1172],\n",
    "    },\n",
    "    \"OE62H\": {\n",
    "        \"Reference\": [0.3530],\n",
    "        \"None\": [0.3431, 0.3513],\n",
    "        \"Transfer\": [0.1670, 0.1507],\n",
    "    },\n",
    "}\n",
    "\n",
    "data_gap = {\n",
    "    \"Test\": {\n",
    "        \"Reference\": [0.0658],\n",
    "        \"None\": [0.9825, 0.9799],\n",
    "        \"Transfer\": [0.0646, 0.0513],\n",
    "    },\n",
    "    \"PC9\": {\n",
    "        \"Reference\": [0.2696],\n",
    "        \"None\": [0.9578, 0.9633],\n",
    "        \"Transfer\": [0.1249, 0.0951],\n",
    "    },\n",
    "    \"OE62L\": {\n",
    "        \"Reference\": [0.5245],\n",
    "        \"None\": [0.5320, 0.5230],\n",
    "        \"Transfer\": [0.2741, 0.2322],\n",
    "    },\n",
    "    \"OE62H\": {\n",
    "        \"Reference\": [0.5187],\n",
    "        \"None\": [0.4427, 0.4112],\n",
    "        \"Transfer\": [0.3116, 0.2559],\n",
    "    }\n",
    "}\n",
    "\n",
    "data = data_lumo\n",
    "data_set = \"OE62H\"\n",
    "data = data[data_set]\n",
    "\n",
    "# Hard-coded categories and N_pre values\n",
    "categories = [\"Reference\", \"None\", \"Transfer\"]\n",
    "N_pre_values = [\"0\", \"1 000 000\", \"5 000 000\"]\n",
    "\n",
    "# Gradient colors\n",
    "cmap = plt.cm.Blues\n",
    "colors = [cmap(i) for i in np.linspace(0.35, 1.05, len(N_pre_values))]\n",
    "\n",
    "# Bar geometry\n",
    "bar_width = 0.25\n",
    "intra_gap = 0.0\n",
    "\n",
    "# Group widths\n",
    "W_group = 2*bar_width + intra_gap   # width of groups with 2 bars\n",
    "W_ref   = bar_width                 # single bar for Reference\n",
    "S_groups = 1.0\n",
    "\n",
    "# X positions\n",
    "x_groups = np.array([1, 2], dtype=float)   # positions for None, Transfer\n",
    "x_ref = x_groups[0] - (S_groups - (W_group - W_ref)/2.0)\n",
    "\n",
    "# Offsets for 2 bars inside a group\n",
    "offsets = np.array([\n",
    "    -W_group/2 + bar_width/2,               # left\n",
    "    -W_group/2 + bar_width/2 + (bar_width + intra_gap)  # right\n",
    "])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# --- Plot Reference (single bar) ---\n",
    "ax.bar(\n",
    "    x_ref,\n",
    "    data[\"Reference\"][0],\n",
    "    width=bar_width,\n",
    "    label=f\"{N_pre_values[0]}\",\n",
    "    color=colors[0]\n",
    ")\n",
    "\n",
    "# --- Plot other categories (2 bars each) ---\n",
    "for i, (N, color) in enumerate(zip(N_pre_values[1:], colors[1:])):  # i = 0..1\n",
    "    vals = [data[cat][i] for cat in categories[1:]]  # None, Transfer\n",
    "    ax.bar(\n",
    "        x_groups + offsets[i],\n",
    "        vals,\n",
    "        width=bar_width,\n",
    "        label=f\"{N}\",\n",
    "        color=color\n",
    "    )\n",
    "\n",
    "# Axes, ticks, legend\n",
    "ax.set_title(data_set, fontname=\"Helvetica\", fontsize=25)\n",
    "ax.set_xlabel(\"Finetuning\", **font)\n",
    "ax.set_ylabel(\"MAE [eV]\", **font)\n",
    "xticks = np.concatenate(([x_ref], x_groups))\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(categories, fontname=\"Helvetica\", fontsize=14)\n",
    "yticks = np.arange(stop=0.9, step=0.1)  # adjust depending on dataset\n",
    "ax.set_yticks(yticks)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.set_ylim(0, yticks[-1])\n",
    "\n",
    "legend = ax.legend(title=\"Number Pretraining Samples\", prop={\"family\": font[\"fontname\"], \"size\": 14})\n",
    "legend.get_title().set_fontsize(14)\n",
    "\n",
    "plt.grid(True, axis=\"y\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plots for talk before and after bitter lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {\"fontname\": \"Helvetica\", \"fontsize\": 20}\n",
    "\n",
    "data_sets = [\"Test\", \"PC9\", \"OE62\"]\n",
    "\n",
    "data = {\n",
    "    \"homo reference\": [0.0518, 0.2074, 0.3751],\n",
    "    \"homo reference 2\": [0.0518, 0.0, 0.0],\n",
    "    \"homo reference 3\": [0.0518, 0.2074, 0.0],\n",
    "    \"gap reference\": [0.0658, 0.2696, 0.5245],\n",
    "    \"gap reference 2\": [0.0658, 0.0, 0.0],\n",
    "    \"gap reference 3\": [0.0658, 0.2696, 0.0],\n",
    "    \"lumo reference\": [0.0338, 0.1258, 0.3075],\n",
    "    \"lumo reference 2\": [0.0338, 0.0, 0.0],\n",
    "    \"lumo reference 3\": [0.0338, 0.1258, 0.0],\n",
    "    \"homo small transfer 5M\": [0.0298, 0.0751, 0.0827],\n",
    "    \"homo small transfer 10M\": [0.0378, 0.0568, 0.0784],\n",
    "    \"gap small transfer 5M\": [0.0513, 0.0951, 0.2322],\n",
    "    \"lumo small transfer 5M\": [0.0321, 0.0530, 0.1172]\n",
    "}\n",
    "\n",
    "all_mae = data[\"gap reference 2\"]\n",
    "\n",
    "# Gradient colors\n",
    "cmap = plt.cm.Blues\n",
    "colors = [cmap(i) for i in np.linspace(0.35, 1.05, 3)]\n",
    "\n",
    "# Bar geometry\n",
    "bar_width = 0.5\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "for i, (data_set, mae) in enumerate(zip(data_sets, all_mae)):\n",
    "    ax.bar(\n",
    "        x=data_set,\n",
    "        height=mae,\n",
    "        width=bar_width,\n",
    "        color=cmap(0.75)\n",
    "    )\n",
    "\n",
    "# Axes, ticks, legend\n",
    "ax.set_title(\"Gap Prediction\", fontname=\"Helvetica\", fontsize=25)\n",
    "ax.set_xlabel(\"Dataset\", **font)\n",
    "ax.set_ylabel(\"MAE [eV]\", **font)\n",
    "ax.set_xticks([0, 1, 2])\n",
    "ax.set_xticklabels(data_sets, fontname=\"Helvetica\", fontsize=14)\n",
    "yticks = np.arange(stop=0.59, step=0.05)  # adjust depending on dataset\n",
    "ax.set_yticks(yticks)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.set_ylim(0, yticks[-1])\n",
    "\n",
    "plt.grid(True, axis=\"y\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction of data demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "N_fine = np.array([10000, 20000, 40000, 80000, 120000])\n",
    "\n",
    "data_homo = {\n",
    "    \"Test\": {\n",
    "        \"with\": np.array([0.0582, 0.0487, 0.0413, 0.0387, 0.0380]),\n",
    "        \"without\": np.array([0.1476, 0.1122, 0.0848, 0.0590, 0.0518]),\n",
    "    },\n",
    "    \"PC9\": {\n",
    "        \"with\": np.array([0.0717, 0.0614, 0.0630, 0.0587, 0.0632]),\n",
    "        \"without\": np.array([0.3693, 0.3231, 0.2735, 0.2220, 0.2074]),\n",
    "    },\n",
    "    \"OE62L\": {\n",
    "        \"with\": np.array([0.1034, 0.1060, 0.0848, 0.0922, 0.0866]),\n",
    "        \"without\": np.array([0.4414, 0.3918, 0.3955, 0.3521, 0.3751]),\n",
    "    },\n",
    "    \"OE62H\": {\n",
    "        \"with\": np.array([0.1149, 0.1247, 0.1024, 0.1079, 0.1041]),\n",
    "        \"without\": np.array([0.6500, 0.6346, 0.5514, 0.4913, 0.4833]),\n",
    "    },\n",
    "}\n",
    "\n",
    "data_gap = {\n",
    "    \"Test\": {\n",
    "        \"with\": np.array([0.0818, 0.0758, 0.0617, 0.0566, 0.0513]),\n",
    "        \"without\": np.array([0.1954, 0.1508, 0.1126, 0.0852, 0.0658]),\n",
    "    },\n",
    "    \"PC9\": {\n",
    "        \"with\": np.array([0.1048, 0.0993, 0.0997, 0.0975, 0.0951]),\n",
    "        \"without\": np.array([0.4708, 0.4017, 0.3596, 0.3081, 0.2696]),\n",
    "    },\n",
    "    \"OE62L\": {\n",
    "        \"with\": np.array([0.2576, 0.2433, 0.2265, 0.2223, 0.2322]),\n",
    "        \"without\": np.array([0.7663, 0.7301, 0.5581, 0.5146, 0.5245]),\n",
    "    },\n",
    "    \"OE62H\": {\n",
    "        \"with\": np.array([0.3109, 0.2924, 0.2736, 0.2478, 0.2559]),\n",
    "        \"without\": np.array([0.7555, 0.6693, 0.5933, 0.5352, 0.5187]),\n",
    "    },\n",
    "}\n",
    "\n",
    "data_lumo = {\n",
    "    \"Test\": {\n",
    "        \"with\": np.array([0.0481, 0.0416, 0.0369, 0.0324, 0.0321]),\n",
    "        \"without\": np.array([0.0893, 0.0749, 0.0569, 0.0364, 0.0338]),\n",
    "    },\n",
    "    \"PC9\": {\n",
    "        \"with\": np.array([0.0638, 0.0585, 0.0540, 0.0539, 0.0530]),\n",
    "        \"without\": np.array([0.1946, 0.1859, 0.1571, 0.1302, 0.1258]),\n",
    "    },\n",
    "    \"OE62L\": {\n",
    "        \"with\": np.array([0.1353, 0.1220, 0.1249, 0.1155, 0.1172]),\n",
    "        \"without\": np.array([0.3743, 0.3521, 0.5381, 0.2970, 0.3075]),\n",
    "    },\n",
    "    \"OE62H\": {\n",
    "        \"with\": np.array([0.1692, 0.1575, 0.1616, 0.1468, 0.1507]),\n",
    "        \"without\": np.array([0.3766, 0.3884, 0.4218, 0.3506, 0.3530]),\n",
    "    },\n",
    "}\n",
    "\n",
    "data = data_homo\n",
    "data_set = \"OE62L\"\n",
    "with_pretraining = data[data_set][\"with\"]\n",
    "without_pretraining = data[data_set][\"without\"]\n",
    "\n",
    "with_pretraining -= with_pretraining[-1]\n",
    "#with_pretraining /= with_pretraining[0]\n",
    "without_pretraining -= without_pretraining[-1]\n",
    "#without_pretraining /= without_pretraining[0]\n",
    "\n",
    "cmap = plt.cm.Blues\n",
    "color1, color2 = cmap(0.5), cmap(1.0)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "font = {\"fontname\": \"Helvetica\", \"fontsize\": 20}\n",
    "\n",
    "ax.plot(N_fine, without_pretraining, label=\"Without Pretraining\", color=color1, marker=\"s\", markersize=8)\n",
    "ax.plot(N_fine, with_pretraining, label=\"With Pretraining\", color=color2, marker=\"o\", markersize=8)\n",
    "\n",
    "ax.set_title(data_set, fontname=\"Helvetica\", fontsize=25)\n",
    "\n",
    "ax.set_xlabel(\"Number of Finetuning Samples\", **font)\n",
    "ax.set_xlim([10000, 120000])\n",
    "xticks = N_fine\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticks, fontname=\"Helvetica\", fontsize=14)\n",
    "\n",
    "y_lower_lim = -0.03\n",
    "y_upper_lim = 0.08\n",
    "step = 0.02\n",
    "ax.set_ylabel(\"MAE [eV]\", **font)\n",
    "#ax.set_ylim([-0.005, without_pretraining[0]+0.01])\n",
    "ax.set_ylim([y_lower_lim, y_upper_lim])\n",
    "#yticks = np.arange(stop=without_pretraining[0], step=0.02)\n",
    "yticks = np.arange(stop=y_upper_lim + step, step=step)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.set_yticks(yticks)\n",
    "#ax.set_ylim([-0.6, 1.0])\n",
    "#ax.tick_params(axis='y', which=\"both\", bottom=False, top=False, left=False, right=False, labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "\n",
    "# Grid + legend\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.6, axis=\"y\")\n",
    "ax.legend(prop={\"family\": font[\"fontname\"], \"size\": 14})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "N_fine = np.array([10000, 20000, 40000, 80000, 120000])\n",
    "\n",
    "data_homo = {\n",
    "    \"Test\": {\n",
    "        \"with\": np.array([0.0582, 0.0487, 0.0413, 0.0387, 0.0380]),\n",
    "        \"with2\": np.array([0.0507, 0.0449, 0.0424, 0.0348, 0.0348]),\n",
    "        \"with3\": np.array([0.0504, 0.0472, 0.0428, 0.0385, 0.0435]),\n",
    "        \"without\": np.array([0.1476, 0.1122, 0.0848, 0.0590, 0.0518]),\n",
    "        \"without2\": np.array([0.1433, 0.1062, 0.0712, 0.0422, 0.0510]),\n",
    "        \"without3\": np.array([0.1459, 0.1063, 0.0738, 0.0447, 0.0449]),\n",
    "    },\n",
    "    \"PC9\": {\n",
    "        \"with\": np.array([0.0717, 0.0614, 0.0630, 0.0587, 0.0632]),\n",
    "        \"with2\": np.array([0.0634, 0.0616, 0.0581, 0.0601, 0.0617]),\n",
    "        \"with3\": np.array([0.0627, 0.0595, 0.0578, 0.0617, 0.0611]),\n",
    "        \"without\": np.array([0.3693, 0.3231, 0.2735, 0.2220, 0.2074]),\n",
    "        \"without2\": np.array([0.4137, 0.3628, 0.3031, 0.2354, 0.2085]),\n",
    "        \"without3\": np.array([0.4303, 0.3633, 0.3067, 0.2284, 0.1944]),\n",
    "    },\n",
    "    \"OE62L\": {\n",
    "        \"with\": np.array([0.1034, 0.1060, 0.0848, 0.0922, 0.0866]),\n",
    "        \"with2\": np.array([0.1147, 0.1025, 0.0896, 0.1032, 0.0883]),\n",
    "        \"with3\": np.array([0.1120, 0.0912, 0.0892, 0.0836, 0.0836]),\n",
    "        \"without\": np.array([0.4414, 0.3918, 0.3955, 0.3521, 0.3751]),\n",
    "        \"without2\": np.array([0.4072, 0.4288, 0.3425, 0.2843, 0.2209]),\n",
    "        \"without3\": np.array([0.3863, 0.3755, 0.3070, 0.2492, 0.2433])\n",
    "    },\n",
    "    \"OE62H\": {\n",
    "        \"with\": np.array([0.1149, 0.1247, 0.1024, 0.1079, 0.1041]),\n",
    "        \"with2\": np.array([0.1399, 0.1246, 0.1108, 0.1263, 0.1091]),\n",
    "        \"with3\": np.array([0.1244, 0.1023, 0.0995, 0.1042, 0.0969]),\n",
    "        \"without\": np.array([0.6500, 0.6346, 0.5514, 0.4913, 0.4833]),\n",
    "        \"without2\": np.array([0.7210, 0.6571, 0.6582, 0.5552, 0.5221]),\n",
    "        \"without3\": np.array([0.7351, 0.6760, 0.6360, 0.5820, 0.5432]),\n",
    "    },\n",
    "}\n",
    "\n",
    "data_gap = {\n",
    "    \"Test\": {\n",
    "        \"with\": np.array([0.0818, 0.0758, 0.0617, 0.0566, 0.0513]),\n",
    "        \"with2\": np.array([0.0745, 0.0715, 0.0638, 0.0479, 0.0536]),\n",
    "        \"with3\": np.array([0.0796, 0.0713, 0.0576, 0.0531, 0.0491]),\n",
    "        \"without\": np.array([0.1954, 0.1508, 0.1126, 0.0852, 0.0658]),\n",
    "        \"without2\": np.array([0.1645, 0.1228, 0.0876, 0.0504, 0.0713]),\n",
    "        \"without3\": np.array([0.1688, 0.1229, 0.0883, 0.0584, 0.0621]),\n",
    "    },\n",
    "    \"PC9\": {\n",
    "        \"with\": np.array([0.1048, 0.0993, 0.0997, 0.0975, 0.0951]),\n",
    "        \"with2\": np.array([0.1013, 0.0967, 0.0934, 0.0995, 0.0985]),\n",
    "        \"with3\": np.array([0.1010, 0.0956, 0.0915, 0.0953, 0.0977]),\n",
    "        \"without\": np.array([0.4708, 0.4017, 0.3596, 0.3081, 0.2696]),\n",
    "        \"without2\": np.array([0.4947, 0.4199, 0.3577, 0.2771, 0.2776]),\n",
    "        \"without3\": np.array([0.4531, 0.3863, 0.3302, 0.2873, 0.2589]),\n",
    "    },\n",
    "    \"OE62L\": {\n",
    "        \"with\": np.array([0.2576, 0.2433, 0.2265, 0.2223, 0.2322]),\n",
    "        \"with2\": np.array([0.2314, 0.2441, 0.2177, 0.2341, 0.2366]),\n",
    "        \"with3\": np.array([0.2535, 0.2391, 0.2154, 0.2199, 0.2176]),\n",
    "        \"without\": np.array([0.7663, 0.7301, 0.5581, 0.5146, 0.5245]),\n",
    "        \"without2\": np.array([0.7058, 0.4988, 0.5382, 0.3844, 0.4513]),\n",
    "        \"without3\": np.array([0.5640, 0.5285, 0.5105, 0.4504, 0.4647]),\n",
    "    },\n",
    "    \"OE62H\": {\n",
    "        \"with\": np.array([0.3109, 0.2924, 0.2736, 0.2478, 0.2559]),\n",
    "        \"with2\": np.array([0.2727, 0.2900, 0.2527, 0.2620, 0.2522]),\n",
    "        \"with3\": np.array([0.3019, 0.2833, 0.2460, 0.2456, 0.2404]),\n",
    "        \"without\": np.array([0.7555, 0.6693, 0.5933, 0.5352, 0.5187]),\n",
    "        \"without2\": np.array([0.8051, 0.6951, 0.6836, 0.5643, 0.5102]),\n",
    "        \"without3\": np.array([0.7060, 0.6513, 0.6020, 0.5179, 0.5123]),\n",
    "    },\n",
    "}\n",
    "\n",
    "data_lumo = {\n",
    "    \"Test\": {\n",
    "        \"with\": np.array([0.0481, 0.0416, 0.0369, 0.0324, 0.0321]),\n",
    "        \"with2\": np.array([0.0486, 0.0410, 0.0394, 0.0302, 0.0298]),\n",
    "        \"with3\": np.array([0.0468, 0.0405, 0.0352, 0.0301, 0.0291]),\n",
    "        \"without\": np.array([0.0893, 0.0749, 0.0569, 0.0364, 0.0338]),\n",
    "        \"without2\": np.array([0.0918, 0.0656, 0.0449, 0.0325, 0.0271]),\n",
    "        \"without3\": np.array([0.0842, 0.0646, 0.0488, 0.0228, 0.0321]),\n",
    "    },\n",
    "    \"PC9\": {\n",
    "        \"with\": np.array([0.0638, 0.0585, 0.0540, 0.0539, 0.0530]),\n",
    "        \"with2\": np.array([0.0631, 0.0574, 0.0548, 0.0518, 0.0522]),\n",
    "        \"with3\": np.array([0.0628, 0.0560, 0.0540, 0.0522, 0.0511]),\n",
    "        \"without\": np.array([0.1946, 0.1859, 0.1571, 0.1302, 0.1258]),\n",
    "        \"without2\": np.array([0.1918, 0.1728, 0.1485, 0.1338, 0.1180]),\n",
    "        \"without3\": np.array([0.1954, 0.1816, 0.1551, 0.1210, 0.1089]),\n",
    "    },\n",
    "    \"OE62L\": {\n",
    "        \"with\": np.array([0.1353, 0.1220, 0.1249, 0.1155, 0.1172]),\n",
    "        \"with2\": np.array([0.1367, 0.1312, 0.1120, 0.1112, 0.1010]),\n",
    "        \"with3\": np.array([0.1365, 0.1201, 0.1128, 0.1106, 0.1035]),\n",
    "        \"without\": np.array([0.3743, 0.3521, 0.5381, 0.2970, 0.3075]),\n",
    "        \"without2\": np.array([0.3381, 0.3014, 0.2576, 0.2864, 0.2720]),\n",
    "        \"without3\": np.array([0.3638, 0.2991, 0.2761, 0.2560, 0.2550]),\n",
    "    },\n",
    "    \"OE62H\": {\n",
    "        \"with\": np.array([0.1692, 0.1575, 0.1616, 0.1468, 0.1507]),\n",
    "        \"with2\": np.array([0.1636, 0.1675, 0.1519, 0.1485, 0.1368]),\n",
    "        \"with3\": np.array([0.1640, 0.1518, 0.1471, 0.1446, 0.1392]),\n",
    "        \"without\": np.array([0.3766, 0.3884, 0.4218, 0.3506, 0.3530]),\n",
    "        \"without2\": np.array([0.3795, 0.3600, 0.3378, 0.3751, 0.3489]),\n",
    "        \"without3\": np.array([0.3921, 0.3621, 0.3471, 0.3371, 0.3274]),\n",
    "    },\n",
    "}\n",
    "\n",
    "data = data_gap\n",
    "data_set = \"OE62H\"\n",
    "with_pretraining = data[data_set][\"with\"]\n",
    "without_pretraining = data[data_set][\"without\"]\n",
    "\n",
    "#'''\n",
    "with_pretraining_2 = data[data_set][\"with2\"]\n",
    "with_pretraining_3 = data[data_set][\"with3\"]\n",
    "without_pretraining_2 = data[data_set][\"without2\"]\n",
    "without_pretraining_3 = data[data_set][\"without3\"]\n",
    "\n",
    "with_pretraining = (with_pretraining + with_pretraining_2 + with_pretraining_3) / 3\n",
    "without_pretraining = (without_pretraining + without_pretraining_2 + without_pretraining_3) / 3\n",
    "#'''\n",
    "\n",
    "with_pretraining -= with_pretraining[-1]\n",
    "#with_pretraining /= with_pretraining[0]\n",
    "without_pretraining -= without_pretraining[-1]\n",
    "#without_pretraining /= without_pretraining[0]\n",
    "\n",
    "cmap = plt.cm.Blues\n",
    "color1, color2 = cmap(0.5), cmap(1.0)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "font = {\"fontname\": \"Helvetica\", \"fontsize\": 20}\n",
    "\n",
    "ax.plot(N_fine, without_pretraining, label=\"Without Pretraining\", color=color1, marker=\"s\", markersize=8)\n",
    "ax.plot(N_fine, with_pretraining, label=\"With Pretraining\", color=color2, marker=\"o\", markersize=8)\n",
    "\n",
    "ax.set_title(data_set, fontname=\"Helvetica\", fontsize=25)\n",
    "\n",
    "ax.set_xlabel(\"Number of Finetuning Samples\", **font)\n",
    "ax.set_xlim([10000, 120000])\n",
    "xticks = N_fine\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticks, fontname=\"Helvetica\", fontsize=14)\n",
    "\n",
    "y_lower_lim = -0.05\n",
    "y_upper_lim = 0.25\n",
    "step = 0.05\n",
    "ax.set_ylabel(\"$\\Delta$MAE [eV]\", **font)\n",
    "#ax.set_ylim([-0.005, without_pretraining[0]+0.01])\n",
    "ax.set_ylim([y_lower_lim, y_upper_lim])\n",
    "#yticks = np.arange(stop=without_pretraining[0], step=0.02)\n",
    "yticks = np.arange(stop=y_upper_lim + step, step=step)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.set_yticks(yticks)\n",
    "#ax.set_ylim([-0.6, 1.0])\n",
    "#ax.tick_params(axis='y', which=\"both\", bottom=False, top=False, left=False, right=False, labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "\n",
    "# Grid + legend\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.6, axis=\"y\")\n",
    "ax.legend(prop={\"family\": font[\"fontname\"], \"size\": 14})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {\"fontname\": \"Helvetica\", \"fontsize\": 14}\n",
    "\n",
    "x = [10000, 20000, 40000, 80000, 120000]\n",
    "y_gwset = []\n",
    "y_pc9 = []\n",
    "plt.scatter(x, y_gwset, label=\"Test\")\n",
    "plt.scatter(x, y_pc9, label=\"PC9\")\n",
    "plt.xticks([0, 20000, 40000, 60000, 80000, 100000, 120000])\n",
    "plt.xlim([0, 125000])\n",
    "plt.xlabel(\"Number of Training Samples\", **font)\n",
    "plt.ylabel(\"MAE [eV]\", **font)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {\"fontname\": \"Helvetica\", \"fontsize\": 14}\n",
    "\n",
    "x = [10000, 20000, 40000, 80000, 120000]\n",
    "y_gwset = [0.1476, 0.1122, 0.0825, 0.0590, 0.0518]\n",
    "y_pc9 = [0.3693, 0.3231, 0.2744, 0.2220, 0.2074]\n",
    "y_pre_gwset = [0.0380]\n",
    "y_pr_pc9 = [0.0632]\n",
    "plt.scatter(x, y_gwset, label=\"Test\")\n",
    "plt.scatter(x, y_pc9, label=\"PC9\")\n",
    "plt.xticks([0, 20000, 40000, 60000, 80000, 100000, 120000])\n",
    "plt.xlim([0, 125000])\n",
    "plt.xlabel(\"Number of Training Samples\", **font)\n",
    "plt.ylabel(\"MAE [eV]\", **font)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining and Finetuning Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {\"fontname\": \"Helvetica\", \"fontsize\": 20}      \n",
    "\n",
    "data_homo = {\n",
    "    \"Test\": [0.0518, 0.0380, 0.0809, 0.0506],\n",
    "    \"PC9\": [0.2074, 0.0632, 0.2215, 0.0910],\n",
    "    \"OE62L\": [0.3751, 0.0866, 0.3004, 0.1179],\n",
    "    \"OE62H\": [0.4833, 0.1041, 0.3971, 0.1330]\n",
    "}\n",
    "\n",
    "data_lumo = {\n",
    "    \"Test\": [0.0338, 0.0577, 0.0321, 0.0370],\n",
    "    \"PC9\": [0.1258, 0.1331, 0.0530, 0.0755],\n",
    "    \"OE62L\": [0.3075, 0.4415, 0.1172, 0.2490],\n",
    "    \"OE62H\": [0.3530, 0.3776, 0.1507, 0.1963]\n",
    "}\n",
    "\n",
    "data_gap = {\n",
    "    \"Test\": [0.0658, 0.0684, 0.0867, 0.0513],\n",
    "    \"PC9\": [0.2696, 0.1505, 0.2374, 0.0951],\n",
    "    \"OE62L\": [0.5245, 0.3452, 0.3177, 0.2322],\n",
    "    \"OE62H\": [0.5187, 0.4097, 0.4287, 0.2559]\n",
    "}\n",
    "\n",
    "target = \"lumo\"\n",
    "\n",
    "if target == \"homo\":\n",
    "    data = data_homo\n",
    "elif target == \"lumo\":\n",
    "    data = data_lumo\n",
    "elif target == \"gap\":\n",
    "    data = data_gap\n",
    "\n",
    "bar_categories = [\"None\", \"Homo\", \"Lumo\", \"Gap\"]\n",
    "categories = [\"Test\", \"PC9\", \"OE62L\", \"OE62H\"]\n",
    "\n",
    "# Gradient colors\n",
    "cmap = plt.cm.Blues\n",
    "colors = [cmap(i) for i in np.linspace(0.35, 1.05, len(bar_categories))]\n",
    "\n",
    "bar_width = 0.35\n",
    "\n",
    "# Group widths\n",
    "W_group = 4*bar_width   # width of groups with 2 bars\n",
    "W_ref   = bar_width                 # single bar for Reference\n",
    "S_groups = 1.0\n",
    "\n",
    "# X positions\n",
    "x_groups = np.array([1, 3, 5, 7], dtype=float)\n",
    "x_ref = x_groups[0] - (S_groups - (W_group - W_ref)/2.0)\n",
    "\n",
    "# Offsets for 2 bars inside a group\n",
    "offsets = np.array([\n",
    "    -W_group/2 + bar_width/2,\n",
    "    -W_group/2 + bar_width/2 + bar_width,\n",
    "     W_group/2 - bar_width/2 - bar_width,\n",
    "     W_group/2 - bar_width/2\n",
    "])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# --- Plot Reference (single bar) ---\n",
    "'''\n",
    "ax.bar(\n",
    "    x_ref,\n",
    "    data[\"Reference\"][0],\n",
    "    width=bar_width,\n",
    "    label=f\"{N_pre_values[0]}\",\n",
    "    color=colors[0]\n",
    ")\n",
    "'''\n",
    "\n",
    "# --- Plot other categories (2 bars each) ---\n",
    "for i, (b_cat, color) in enumerate(zip(bar_categories, colors)):  # i = 0..1\n",
    "    vals = [data[cat][i] for cat in categories]\n",
    "    ax.bar(\n",
    "        x_groups + offsets[i],\n",
    "        vals,\n",
    "        width=bar_width,\n",
    "        label=f\"{b_cat}\",\n",
    "        color=color\n",
    "    )\n",
    "\n",
    "# Axes, ticks, legend\n",
    "ax.set_title(target.title(), fontname=\"Helvetica\", fontsize=25)\n",
    "ax.set_xlabel(\"Dataset\", **font)\n",
    "ax.set_ylabel(\"MAE [eV]\", **font)\n",
    "#xticks = np.concatenate(([x_ref], x_groups))\n",
    "xticks = x_groups\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(categories, fontname=\"Helvetica\", fontsize=14)\n",
    "yticks = np.arange(stop=0.65, step=0.1)  # adjust depending on dataset\n",
    "ax.set_yticks(yticks)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.set_ylim(0, yticks[-1])\n",
    "\n",
    "legend = ax.legend(title=\"Pretraining Targets\", prop={\"family\": font[\"fontname\"], \"size\": 14})\n",
    "legend.get_title().set_fontsize(14)\n",
    "\n",
    "plt.grid(True, axis=\"y\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction MAE on QM9GW vs. on OMol25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = \"PC9\"\n",
    "target = \"homo\"\n",
    "\n",
    "logs_path = f\"/Volumes/LaCie/trained_models/ViSNet/{target}0M128502532\"\n",
    "ckpt_name = \"model_45_epochs\"\n",
    "model = load_model(logs_path, ckpt_name)\n",
    "\n",
    "logs_path = f\"/Volumes/LaCie/trained_models/ViSNet/{target}5M128502532_transfer_converged/visnet_logs\"\n",
    "ckpt_name = \"model_30_epochs\"\n",
    "pretrained_model = load_model(logs_path, ckpt_name)\n",
    "\n",
    "xyz_path = os.path.join(\"/Volumes/LaCie/test_sets\", test_set, \"mols\")\n",
    "gw_path = os.path.join(\"/Volumes/LaCie/test_sets\", test_set, \"E_qp\")\n",
    "omol25_path = os.path.join(\"/Volumes/LaCie/test_sets\", test_set, \"E_omol25\")\n",
    "\n",
    "xyz_files = os.listdir(xyz_path)\n",
    "all_mae_gw = []\n",
    "all_mae_omol25 = []\n",
    "all_mae_gw_pretrain = []\n",
    "all_mae_omol25_pretrain = []\n",
    "with torch.no_grad():\n",
    "    for xyz_file in tqdm(xyz_files, leave=False):\n",
    "        mol = xyz_file[:-4]\n",
    "        atoms = read(f\"{xyz_path}/{xyz_file}\", format=\"xyz\")\n",
    "        homo_idx = int(np.sum(atoms.get_atomic_numbers()) // 2 - 1)\n",
    "        e_gw = np.loadtxt(f\"{gw_path}/{mol}.dat\")\n",
    "        e_omol25 = np.loadtxt(f\"{omol25_path}/{mol}.dat\")\n",
    "        if target == \"homo\":\n",
    "            y_gw = float(e_gw[homo_idx])\n",
    "            y_omol25 = float(e_omol25[0])\n",
    "        elif target == \"lumo\":\n",
    "            y_gw = float(e_gw[homo_idx + 1])\n",
    "            y_omol25 = float(e_omol25[1])\n",
    "        elif target == \"gap\":\n",
    "            y_gw = float(e_gw[homo_idx + 1]) - float(e_gw[homo_idx])\n",
    "            y_omol25 = float(e_omol25[1]) - float(e_omol25[0])\n",
    "        Z = torch.from_numpy(atoms.get_atomic_numbers())\n",
    "        R = torch.from_numpy(atoms.get_positions()).to(dtype=torch.float32)\n",
    "        B = torch.zeros((len(atoms),)).to(dtype=torch.int64)\n",
    "        data = {\"z\": Z, \"pos\": R, \"batch\": B}\n",
    "        y_pred, _ = model(data)\n",
    "        y_pred = y_pred.item()\n",
    "        y_pred_pretrain, _ = pretrained_model(data)\n",
    "        y_pred_pretrain = y_pred_pretrain.item()\n",
    "        all_mae_gw.append(abs(y_pred - y_gw))\n",
    "        all_mae_omol25.append(abs(y_pred - y_omol25))\n",
    "        all_mae_gw_pretrain.append(abs(y_pred_pretrain - y_gw))\n",
    "        all_mae_omol25_pretrain.append(abs(y_pred_pretrain - y_omol25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Font dictionary\n",
    "font = {\"fontname\": \"Helvetica\", \"fontsize\": 20}\n",
    "cmap = plt.cm.Blues\n",
    "\n",
    "# Scatter plots\n",
    "ax.scatter(all_mae_gw, all_mae_omol25, label=\"Without Pretraining\", s=30, color=cmap(0.5))\n",
    "ax.scatter(all_mae_gw_pretrain, all_mae_omol25_pretrain, label=\"With Pretraining\", s=30, color=cmap(0.9))\n",
    "\n",
    "# Title\n",
    "ax.set_title(\"PC9\", fontname=\"Helvetica\", fontsize=25)\n",
    "\n",
    "# X-axis\n",
    "ax.set_xlabel(\"MAE QM9GW [eV]\", **font)\n",
    "ax.set_xlim([0, 2])\n",
    "xticks = np.arange(0, 2.2, 0.2)\n",
    "xticks = [float(f\"{x:.1f}\") for x in xticks]\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticks, fontsize=14)\n",
    "\n",
    "# Y-axis\n",
    "ax.set_ylabel(\"MAE OMol25 [eV]\", **font)\n",
    "ax.set_ylim([0, 2])\n",
    "yticks = np.arange(0, 2.2, 0.2)\n",
    "ax.set_yticks(yticks)\n",
    "ax.tick_params(axis=\"y\", labelsize=14)\n",
    "\n",
    "# Legend\n",
    "ax.legend(prop={\"family\": font[\"fontname\"], \"size\": 14}, loc=\"upper right\",  frameon=True, framealpha=1, edgecolor=\"black\")\n",
    "\n",
    "# Layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions:\n",
    "#\n",
    "# case 1_1: y_gwset < y_omol25 < y_pred\n",
    "# case 1_2: y_pred < y_omol25 < y_gwset\n",
    "#\n",
    "# case 2_1: y_omol25 < y_gwset < y_pred\n",
    "# case 2_2: y_pred < y_gwset < y_omol25\n",
    "#\n",
    "# case 3_1: y_gwset < y_pred < y_omol25\n",
    "# case 3_2: y_omol25 < y_pred < y_gwset\n",
    "\n",
    "target = \"homo\"\n",
    "lacie_conn = os.path.exists(\"/Volumes/LaCie\")\n",
    "pc9_path = \"../test_datasets/PC9\"\n",
    "\n",
    "xyz_files = os.listdir(f\"{pc9_path}/mols\")\n",
    "\n",
    "mae_gwset_case_1_1 = []\n",
    "mae_omol25_case_1_1 = []\n",
    "mae_gwset_case_1_2 = []\n",
    "mae_omol25_case_1_2 = []\n",
    "\n",
    "mae_gwset_case_2_1 = []\n",
    "mae_omol25_case_2_1 = []\n",
    "mae_gwset_case_2_2 = []\n",
    "mae_omol25_case_2_2 = []\n",
    "\n",
    "mae_gwset_case_3_1 = []\n",
    "mae_omol25_case_3_1 = []\n",
    "mae_gwset_case_3_2 = []\n",
    "mae_omol25_case_3_2 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xyz_file in xyz_files:\n",
    "        mol = xyz_file[:-4]\n",
    "        atoms = read(f\"{pc9_path}/mols/{xyz_file}\", format=\"xyz\")\n",
    "        homo_idx = int(np.sum(atoms.get_atomic_numbers()) // 2 - 1)\n",
    "        e_qp = np.loadtxt(f\"{pc9_path}/E_qp/{mol}.dat\")\n",
    "        e_dft = np.loadtxt(f\"{pc9_path}/E_omol25/{mol}.dat\")\n",
    "        if target == \"homo\":\n",
    "            y_gw = float(e_qp[homo_idx])\n",
    "            y_dft = float(e_dft[0])\n",
    "        elif target == \"lumo\":\n",
    "            y_gw = float(e_qp[homo_idx+1])\n",
    "            y_dft = float(e_dft[1])\n",
    "        Z = torch.from_numpy(atoms.get_atomic_numbers())\n",
    "        R = torch.from_numpy(atoms.get_positions()).to(dtype=torch.float32)\n",
    "        B = torch.zeros((len(atoms),)).to(dtype=torch.int64)\n",
    "        data = {\"z\": Z, \"pos\": R, \"batch\": B}\n",
    "        y_pred, _ = model(data)\n",
    "        y_pred = y_pred.item()\n",
    "        mae_gw = abs(y_pred - y_gw)\n",
    "        mae_dft = abs(y_pred - y_dft)\n",
    "        if y_gw < y_dft < y_pred:\n",
    "            mae_gwset_case_1_1.append(mae_gw)\n",
    "            mae_omol25_case_1_1.append(mae_dft)\n",
    "        elif y_pred < y_dft < y_gw:\n",
    "            mae_gwset_case_1_2.append(mae_gw)\n",
    "            mae_omol25_case_1_2.append(mae_dft)\n",
    "        elif y_dft < y_gw < y_pred:\n",
    "            mae_gwset_case_2_1.append(mae_gw)\n",
    "            mae_omol25_case_2_1.append(mae_dft)\n",
    "        elif y_pred < y_gw < y_dft:\n",
    "            mae_gwset_case_2_2.append(mae_gw)\n",
    "            mae_omol25_case_2_2.append(mae_dft)\n",
    "        elif y_gw < y_pred < y_dft:\n",
    "            mae_gwset_case_3_1.append(mae_gw)\n",
    "            mae_omol25_case_3_1.append(mae_dft)\n",
    "        elif y_dft < y_pred < y_gw:\n",
    "            mae_gwset_case_3_2.append(mae_gw)\n",
    "            mae_omol25_case_3_2.append(mae_dft)\n",
    "    if lacie_conn:\n",
    "        pc9_path = \"/Volumes/LaCie/test_sets/PC9\"\n",
    "        xyz_files = os.listdir(f\"{pc9_path}/mols\")\n",
    "        for xyz_file in xyz_files:\n",
    "            mol = xyz_file[:-4]\n",
    "            atoms = read(f\"{pc9_path}/mols/{xyz_file}\", format=\"xyz\")\n",
    "            homo_idx = int(np.sum(atoms.get_atomic_numbers()) // 2 - 1)\n",
    "            e_qp = np.loadtxt(f\"{pc9_path}/E_qp/{mol}.dat\")\n",
    "            e_dft = np.loadtxt(f\"{pc9_path}/E_omol25/{mol}.dat\")\n",
    "            if target == \"homo\":\n",
    "                y_gw = float(e_qp[homo_idx])\n",
    "                y_dft = float(e_dft[0])\n",
    "            elif target == \"lumo\":\n",
    "                y_gw = float(e_qp[homo_idx+1])\n",
    "                y_dft = float(e_dft[1])\n",
    "            Z = torch.from_numpy(atoms.get_atomic_numbers())\n",
    "            R = torch.from_numpy(atoms.get_positions()).to(dtype=torch.float32)\n",
    "            B = torch.zeros((len(atoms),)).to(dtype=torch.int64)\n",
    "            data = {\"z\": Z, \"pos\": R, \"batch\": B}\n",
    "            y_pred, _ = model(data)\n",
    "            y_pred = y_pred.item()\n",
    "            mae_gw = abs(y_pred - y_gw)\n",
    "            mae_dft = abs(y_pred - y_dft)\n",
    "            if y_gw < y_dft < y_pred:\n",
    "                mae_gwset_case_1_1.append(mae_gw)\n",
    "                mae_omol25_case_1_1.append(mae_dft)\n",
    "            elif y_pred < y_dft < y_gw:\n",
    "                mae_gwset_case_1_2.append(mae_gw)\n",
    "                mae_omol25_case_1_2.append(mae_dft)\n",
    "            elif y_dft < y_gw < y_pred:\n",
    "                mae_gwset_case_2_1.append(mae_gw)\n",
    "                mae_omol25_case_2_1.append(mae_dft)\n",
    "            elif y_pred < y_gw < y_dft:\n",
    "                mae_gwset_case_2_2.append(mae_gw)\n",
    "                mae_omol25_case_2_2.append(mae_dft)\n",
    "            elif y_gw < y_pred < y_dft:\n",
    "                mae_gwset_case_3_1.append(mae_gw)\n",
    "                mae_omol25_case_3_1.append(mae_dft)\n",
    "            elif y_dft < y_pred < y_gw:\n",
    "                mae_gwset_case_3_2.append(mae_gw)\n",
    "                mae_omol25_case_3_2.append(mae_dft)\n",
    "\n",
    "'''\n",
    "data = {\n",
    "    \"mol\": all_mols,\n",
    "    \"y_pred\": all_y_pred,\n",
    "    \"y_gw\": all_y_gw,\n",
    "    \"mae_gw\": all_mae_gw,\n",
    "    \"y_dft\": all_y_dft,\n",
    "    \"mae_dft\": all_mae_dft,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(f\"Mean = {np.mean(all_mae_gw):.4f} +-({np.std(all_mae_gw):.4f}) eV\")\n",
    "print(f\"Median = {np.median(all_mae_gw):.4f} eV\")\n",
    "print(f\"Min. MAE = {min_mae_gw:.4f} eV for {min_mol_gw}\")\n",
    "print(f\"Max. MAE = {max_mae_gw:.4f} eV for {max_mol_gw}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(mae_gwset_case_1_1, mae_omol25_case_1_1, c=\"#7aa457\") # y_gwset < y_omol25 < y_pred\n",
    "plt.scatter(mae_gwset_case_1_2, mae_omol25_case_1_2, c=\"#496234\") # y_pred < y_omol25 < y_gwset\n",
    "plt.scatter(mae_gwset_case_2_1, mae_omol25_case_2_1, c=\"#9e6ebd\") # y_omol25 < y_gwset < y_pred\n",
    "plt.scatter(mae_gwset_case_2_2, mae_omol25_case_2_2, c=\"#5f4271\") # y_pred < y_gwset < y_omol25\n",
    "plt.scatter(mae_gwset_case_3_1, mae_omol25_case_3_1, c=\"#cb6751\") # y_gwset < y_pred < y_omol25\n",
    "plt.scatter(mae_gwset_case_3_2, mae_omol25_case_3_2, c=\"#7a3d31\") # y_omol25 < y_pred < y_gwset\n",
    "plt.xlabel(\"MAE GWSet [eV]\")\n",
    "plt.ylabel(\"MAE OMol25 [eV]\")\n",
    "plt.xlim([0, 2])\n",
    "plt.ylim([0, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(mae_gwset_case_1_1, mae_omol25_case_1_1, label=\"case 1\") # y_gwset < y_omol25 < y_pred\n",
    "#plt.scatter(mae_gwset_case_1_2, mae_omol25_case_1_2, label=\"case 2\") # y_pred < y_omol25 < y_gwset\n",
    "#plt.scatter(mae_gwset_case_2_1, mae_omol25_case_2_1, label=\"case 1\") # y_omol25 < y_gwset < y_pred\n",
    "#plt.scatter(mae_gwset_case_2_2, mae_omol25_case_2_2, label=\"case 2\") # y_pred < y_gwset < y_omol25\n",
    "plt.scatter(mae_gwset_case_3_1, mae_omol25_case_3_1, label=\"case 1\") # y_gwset < y_pred < y_omol25\n",
    "plt.scatter(mae_gwset_case_3_2, mae_omol25_case_3_2, label=\"case 2\") # y_omol25 < y_pred < y_gwset\n",
    "plt.xlabel(\"MAE GWSet [eV]\")\n",
    "plt.ylabel(\"MAE OMol25 [eV]\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(mae_gwset_case_1_1, mae_omol25_case_1_1, c=\"#7aa457\") # y_gwset < y_omol25 < y_pred\n",
    "plt.scatter(mae_gwset_case_1_2, mae_omol25_case_1_2, c=\"#496234\") # y_pred < y_omol25 < y_gwset\n",
    "plt.scatter(mae_gwset_case_2_1, mae_omol25_case_2_1, c=\"#9e6ebd\") # y_omol25 < y_gwset < y_pred\n",
    "plt.scatter(mae_gwset_case_2_2, mae_omol25_case_2_2, c=\"#5f4271\") # y_pred < y_gwset < y_omol25\n",
    "plt.scatter(mae_gwset_case_3_1, mae_omol25_case_3_1, c=\"#cb6751\") # y_gwset < y_pred < y_omol25\n",
    "plt.scatter(mae_gwset_case_3_2, mae_omol25_case_3_2, c=\"#7a3d31\") # y_omol25 < y_pred < y_gwset\n",
    "plt.xlabel(\"MAE GWSet [eV]\")\n",
    "plt.ylabel(\"MAE OMol25 [eV]\")\n",
    "plt.xlim([0, 2])\n",
    "plt.ylim([0, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(mae_gwset_case_1_1, mae_omol25_case_1_1, label=\"case 1\") # y_gwset < y_omol25 < y_pred\n",
    "#plt.scatter(mae_gwset_case_1_2, mae_omol25_case_1_2, label=\"case 2\") # y_pred < y_omol25 < y_gwset\n",
    "#plt.scatter(mae_gwset_case_2_1, mae_omol25_case_2_1, label=\"case 1\") # y_omol25 < y_gwset < y_pred\n",
    "#plt.scatter(mae_gwset_case_2_2, mae_omol25_case_2_2, label=\"case 2\") # y_pred < y_gwset < y_omol25\n",
    "plt.scatter(mae_gwset_case_3_1, mae_omol25_case_3_1, label=\"case 1\") # y_gwset < y_pred < y_omol25\n",
    "plt.scatter(mae_gwset_case_3_2, mae_omol25_case_3_2, label=\"case 2\") # y_omol25 < y_pred < y_gwset\n",
    "plt.xlabel(\"MAE GWSet [eV]\")\n",
    "plt.ylabel(\"MAE OMol25 [eV]\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logs_path = \"../visnet_logs\"\n",
    "logs_path = \"/Volumes/LaCie/trained_models/ViSNet/homo0M216502532\"\n",
    "ckpt_name = \"best_model\"\n",
    "#ckpt_name = \"model_10_epochs\"\n",
    "\n",
    "model = load_model(logs_path, ckpt_name)\n",
    "\n",
    "#logs_path = \"../visnet_logs\"\n",
    "logs_path = \"/Volumes/LaCie/trained_models/ViSNet/homo10M216502532_best/visnet_logs\"\n",
    "#ckpt_name = \"best_model\"\n",
    "ckpt_name = \"model_10_epochs\"\n",
    "\n",
    "pretrained_model = load_model(logs_path, ckpt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(all_mae_gwset, all_mae_omol25, label=\"Without Pretraining\", s=15.0)\n",
    "plt.scatter(all_mae_gwset_pretrain, all_mae_omol25_pretrain, label=\"With Pretraining\", s=15.0)\n",
    "plt.xlabel(\"MAE GWSet [eV]\")\n",
    "plt.ylabel(\"MAE OMol25 [eV]\")\n",
    "plt.xlim([0, 2])\n",
    "plt.ylim([0, 2])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = \"../visnet_logs\"\n",
    "#logs_path = \"/Volumes/LaCie/trained_models/ViSNet/prehomo10M216502532\"\n",
    "#ckpt_name = \"best_model\"\n",
    "ckpt_name = \"model_5_epochs\"\n",
    "\n",
    "target = \"gap\"\n",
    "lacie_conn = os.path.exists(\"/Volumes/LaCie\")\n",
    "pc9_path = \"../test_datasets/PC9\"\n",
    "\n",
    "xyz_files = os.listdir(f\"{pc9_path}/mols\")\n",
    "model = load_model(logs_path, ckpt_name)\n",
    "\n",
    "all_target = []\n",
    "all_pred = []\n",
    "all_mae_pc9 = []\n",
    "all_mae_omol25 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xyz_file in xyz_files:\n",
    "        mol = xyz_file[:-4]\n",
    "        atoms = read(f\"{pc9_path}/mols/{xyz_file}\", format=\"xyz\")\n",
    "        homo_idx = int(np.sum(atoms.get_atomic_numbers()) // 2 - 1)\n",
    "        e_qp = np.loadtxt(f\"{pc9_path}/E_qp/{mol}.dat\")\n",
    "        e_dft = np.loadtxt(f\"{pc9_path}/E_omol25/{mol}.dat\")\n",
    "        if target == \"homo\":\n",
    "            y_gw = float(e_qp[homo_idx])\n",
    "            y_dft = float(e_dft[0])\n",
    "        elif target == \"lumo\":\n",
    "            y_gw = float(e_qp[homo_idx+1])\n",
    "            y_dft = float(e_dft[1])\n",
    "        elif target == \"gap\":\n",
    "            homo_gw = float(e_qp[homo_idx])\n",
    "            homo_dft = float(e_dft[0])\n",
    "            lumo_gw = float(e_qp[homo_idx+1])\n",
    "            lumo_dft = float(e_dft[1])\n",
    "            y_gw = lumo_gw - homo_gw\n",
    "            y_dft= lumo_dft - homo_dft\n",
    "        Z = torch.from_numpy(atoms.get_atomic_numbers())\n",
    "        R = torch.from_numpy(atoms.get_positions()).to(dtype=torch.float32)\n",
    "        B = torch.zeros((len(atoms),)).to(dtype=torch.int64)\n",
    "        data = {\"z\": Z, \"pos\": R, \"batch\": B}\n",
    "        y_pred, _ = model(data)\n",
    "        y_pred = y_pred.item()\n",
    "        mae_gw = abs(y_pred - y_gw)\n",
    "        mae_dft = abs(y_pred - y_dft)\n",
    "        all_mae_pc9.append(mae_gw)\n",
    "        all_mae_omol25.append(mae_dft)\n",
    "        all_target.append(y_gw)\n",
    "        all_pred.append(y_pred)\n",
    "    if lacie_conn:\n",
    "        pc9_path = \"/Volumes/LaCie/test_sets/PC9\"\n",
    "        xyz_files = os.listdir(f\"{pc9_path}/mols\")\n",
    "        for xyz_file in xyz_files:\n",
    "            mol = xyz_file[:-4]\n",
    "            atoms = read(f\"{pc9_path}/mols/{xyz_file}\", format=\"xyz\")\n",
    "            homo_idx = int(np.sum(atoms.get_atomic_numbers()) // 2 - 1)\n",
    "            e_qp = np.loadtxt(f\"{pc9_path}/E_qp/{mol}.dat\")\n",
    "            e_dft = np.loadtxt(f\"{pc9_path}/E_omol25/{mol}.dat\")\n",
    "            if target == \"homo\":\n",
    "                y_gw = float(e_qp[homo_idx])\n",
    "                y_dft = float(e_dft[0])\n",
    "            elif target == \"lumo\":\n",
    "                y_gw = float(e_qp[homo_idx+1])\n",
    "                y_dft = float(e_dft[1])\n",
    "            elif target == \"gap\":\n",
    "                homo_gw = float(e_qp[homo_idx])\n",
    "                homo_dft = float(e_dft[0])\n",
    "                lumo_gw = float(e_qp[homo_idx+1])\n",
    "                lumo_dft = float(e_dft[1])\n",
    "                y_gw = lumo_gw - homo_gw\n",
    "                y_dft= lumo_dft - homo_dft\n",
    "            Z = torch.from_numpy(atoms.get_atomic_numbers())\n",
    "            R = torch.from_numpy(atoms.get_positions()).to(dtype=torch.float32)\n",
    "            B = torch.zeros((len(atoms),)).to(dtype=torch.int64)\n",
    "            data = {\"z\": Z, \"pos\": R, \"batch\": B}\n",
    "            y_pred, _ = model(data)\n",
    "            y_pred = y_pred.item()\n",
    "            mae_gw = abs(y_pred - y_gw)\n",
    "            mae_dft = abs(y_pred - y_dft)\n",
    "            all_mae_pc9.append(mae_gw)\n",
    "            all_mae_omol25.append(mae_dft)\n",
    "            all_target.append(y_gw)\n",
    "            all_pred.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_target, bins=50, density=True, label=\"Target\")\n",
    "plt.hist(all_pred, bins=50, density=True, label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_target, bins=50, density=True, label=\"Target\")\n",
    "plt.hist(all_pred, bins=50, density=True, label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
